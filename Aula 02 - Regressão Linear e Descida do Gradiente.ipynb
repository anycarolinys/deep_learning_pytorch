{"cells":[{"cell_type":"markdown","metadata":{},"source":["Referência da aula: https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans/lesson/lesson-1-pytorch-basics-and-linear-regression"]},{"cell_type":"markdown","metadata":{"id":"QuFdAKZS_yjn"},"source":["# **Introdução à regressão linear**\n","\n","Neste tutorial, discutiremos um dos algoritmos fundamentais do aprendizado de máquina: *Regressão linear*. Criaremos um modelo que prevê o rendimento das safras de maçãs e laranjas (*variáveis-alvo*) observando a temperatura média, a precipitação e a umidade (*variáveis de entrada ou features*) em uma região. Aqui estão os dados de treinamento:\n","\n","![linear-regression-training-data](https://i.imgur.com/6Ujttb4.png)\n","\n","Em um modelo de regressão linear, cada variável-alvo é estimada como uma soma ponderada das variáveis de entrada, compensada por alguma constante, conhecida como viés:\n","\n","```\n","yield_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n","yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n","```\n","\n","Visualmente, isso significa que o rendimento das maçãs é uma função linear ou plana da temperatura, da precipitação e da umidade:\n","\n","![linear-regression-graph](https://i.imgur.com/4DJ9f8X.png)"]},{"cell_type":"markdown","metadata":{"id":"Nfe0glPiEoGp"},"source":["A parte de *aprendizado* da regressão linear consiste em descobrir um conjunto de pesos `w11, w12,... w23, b1 e b2` usando os dados de treinamento para fazer previsões precisas para novos dados. Os pesos _aprendidos_ serão usados para prever a produção de maçãs e laranjas em uma nova região usando a temperatura média, a precipitação e a umidade dessa região.\n","\n","Vamos _treinar_ nosso modelo ajustando ligeiramente os pesos várias vezes para fazer previsões melhores, usando uma técnica de otimização chamada *gradient descent*. Vamos começar importando o Numpy e o PyTorch."]},{"cell_type":"code","execution_count":62,"metadata":{"executionInfo":{"elapsed":569,"status":"ok","timestamp":1717608403578,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"497YAZHOFXlz"},"outputs":[],"source":["import numpy as np\n","import torch"]},{"cell_type":"code","execution_count":63,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1717608404215,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"A9d5puDtFkHx"},"outputs":[],"source":["# Input (temp, rainfall, humidity)\n","inputs = np.array([[73, 67, 43],\n","                   [91, 88, 64],\n","                   [87, 134, 58],\n","                   [102, 43, 37],\n","                   [69, 96, 70]], dtype='float32')"]},{"cell_type":"code","execution_count":64,"metadata":{"executionInfo":{"elapsed":37,"status":"ok","timestamp":1717608404216,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"AJ9tYeNAFmuT"},"outputs":[],"source":["# Targets (apples, oranges)\n","targets = np.array([[56, 70],\n","                    [81, 101],\n","                    [119, 133],\n","                    [22, 37],\n","                    [103, 119]], dtype='float32')"]},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1717608404216,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"Gz_BsZIJFxMg","outputId":"c45812bb-d682-4b0d-d98c-d5184516bc33"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 73.,  67.,  43.],\n","        [ 91.,  88.,  64.],\n","        [ 87., 134.,  58.],\n","        [102.,  43.,  37.],\n","        [ 69.,  96.,  70.]])\n","tensor([[ 56.,  70.],\n","        [ 81., 101.],\n","        [119., 133.],\n","        [ 22.,  37.],\n","        [103., 119.]])\n"]}],"source":["inputs = torch.from_numpy(inputs)\n","targets = torch.from_numpy(targets)\n","print(inputs)\n","print(targets)"]},{"cell_type":"markdown","metadata":{"id":"K98Qy_awGKD3"},"source":["# **Regressão Linear do Zero**"]},{"cell_type":"code","execution_count":66,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1717608404216,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"c-ovPK71GZkf","outputId":"86fb6e42-447c-4244-f359-95b33a251eba"},"outputs":[{"data":{"text/plain":["(tensor([[ 1.8899,  0.7672,  0.8527],\n","         [-1.0839,  0.0552,  1.3619]], requires_grad=True),\n"," tensor([ 1.5510, -0.7765], requires_grad=True))"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["weight = torch.randn(2,3, requires_grad=True)\n","bias = torch.randn(2,requires_grad=True)\n","\n","weight, bias"]},{"cell_type":"markdown","metadata":{"id":"qEw81Zk7G9x7"},"source":["> Definindo o modelo:"]},{"cell_type":"markdown","metadata":{"id":"zOatmo5JHfxq"},"source":["> - Inicializando os pesos e os vieses como sendo matriz e vetor, respectivamente  \n","> - Definindo-os como valores aleatórios pois ainda não é possível saber quais são os valores ideiais para essas features"]},{"cell_type":"code","execution_count":67,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1717608404216,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"VwFMuKSpJrnI","outputId":"966c8cfe-1153-4c27-af3d-68c39449c5fe"},"outputs":[{"data":{"text/plain":["tensor([[227.5801, -17.6408],\n","        [295.6157,  -7.3921],\n","        [318.2291,  -8.6863],\n","        [258.8593, -58.5713],\n","        [265.2914,  25.0671]], grad_fn=<AddBackward0>)"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["inputs @ weight.t() + bias"]},{"cell_type":"markdown","metadata":{"id":"CkcuBtUqKEZW"},"source":["> O vetor de exemplo da função acima representa a previsão da produção de maçãs e laranjas, respectivamente para cada uma das 5 regiões."]},{"cell_type":"code","execution_count":68,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1717608404216,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"QTrX_d9UJZc7"},"outputs":[],"source":["def model(x):\n","  return x @ weight.t() + bias"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1717608404216,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"--Ki8hNpJk3I","outputId":"8acf3df7-ca50-412a-de63-ab787ff870e2"},"outputs":[{"data":{"text/plain":["tensor([[227.5801, -17.6408],\n","        [295.6157,  -7.3921],\n","        [318.2291,  -8.6863],\n","        [258.8593, -58.5713],\n","        [265.2914,  25.0671]], grad_fn=<AddBackward0>)"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["predictions = model(inputs)\n","predictions"]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1717608404216,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"7ZmVCbPdTm9u","outputId":"93488ff8-2c7f-4c22-ac6c-907700f417c7"},"outputs":[{"data":{"text/plain":["tensor([[ 56.,  70.],\n","        [ 81., 101.],\n","        [119., 133.],\n","        [ 22.,  37.],\n","        [103., 119.]])"]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["targets"]},{"cell_type":"code","execution_count":71,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1717608404216,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"qPyBAz_hU2f-","outputId":"f6c2acca-9fdc-4bef-d09e-1626f62e3503"},"outputs":[{"data":{"text/plain":["tensor(25509.4688, grad_fn=<DivBackward0>)"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["diff = predictions - targets\n","torch.sum(diff * diff) / diff.numel()"]},{"cell_type":"markdown","metadata":{"id":"NBLeo8MEUtIM"},"source":["# **Função de Perda (Loss)**\n","\n","Antes de aprimorarmos nosso modelo, precisamos de uma maneira de avaliar o desempenho do nosso modelo. Podemos comparar as previsões do modelo com os alvos reais usando o seguinte método:\n","\n","* Calcule a diferença entre as duas matrizes (`predictions` e `targets`).\n","* Eleve todos os elementos da matriz de diferença ao quadrado para remover os valores negativos.\n","* Calcular a média dos elementos na matriz resultante.\n","\n","O resultado é um único número, conhecido como *mean squared error* (MSE)."]},{"cell_type":"code","execution_count":72,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1717608404216,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"gqLa_IRfXIRu"},"outputs":[],"source":["def mse(preds, targets):\n","  diff = preds - targets\n","  return torch.sum(diff * diff) / diff.numel()"]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1717608404216,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"8tuL3liP65X5","outputId":"d60e337b-058c-4f60-8685-e334d37da7f2"},"outputs":[{"data":{"text/plain":["tensor(25509.4688, grad_fn=<DivBackward0>)"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["loss = mse(predictions, targets)\n","loss"]},{"cell_type":"markdown","metadata":{"id":"EXtz-KCu8CAG"},"source":["Veja como podemos interpretar o resultado: *Em média, cada elemento da previsão difere da meta real pela raiz quadrada da perda*. E isso é muito ruim, considerando que os números que estamos tentando prever estão na faixa de 50 a 200. O resultado é chamado de *perda* porque indica o quanto o modelo é ruim na previsão das variáveis-alvo. Ele representa a perda de informações no modelo: quanto menor a perda, melhor o modelo."]},{"cell_type":"markdown","metadata":{"id":"KKBmJeylAo6m"},"source":["# **Calcular gradientes**\n","\n","Com o PyTorch, podemos calcular automaticamente o gradiente ou a derivada da perda em relação aos pesos e vieses porque eles têm `requires_grad` definido como `True`. Veremos como isso é útil daqui a pouco."]},{"cell_type":"code","execution_count":74,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1717608404216,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"lLwE_5Fk88zm"},"outputs":[],"source":["loss.backward()"]},{"cell_type":"code","execution_count":75,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1717608404216,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"MhwJ0u-q9BEe","outputId":"3bed927b-4ba7-430d-d0e4-cc164b85b28f"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 1.8899,  0.7672,  0.8527],\n","        [-1.0839,  0.0552,  1.3619]], requires_grad=True)\n","tensor([[16949.2109, 16568.7324, 10558.5654],\n","        [-8963.5625, -9504.7051, -5806.9795]])\n"]}],"source":["print(weight)\n","print(weight.grad)"]},{"cell_type":"code","execution_count":76,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1717608404216,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"fpRLNolG9Fgv","outputId":"f592b111-00e4-4ba3-a13d-2d04991301a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([ 1.5510, -0.7765], requires_grad=True)\n","tensor([ 196.9151, -105.4447])\n"]}],"source":["print(bias)\n","print(bias.grad)"]},{"cell_type":"markdown","metadata":{"id":"kMR_7zbNBaZ9"},"source":["# **Ajuste pesos e preconceitos para reduzir a perda**\n","\n","A perda (loss) é uma [função quadrática](https://en.wikipedia.org/wiki/Quadratic_function) de nossos pesos e vieses, e nosso objetivo é encontrar o conjunto de pesos onde a perda é menor. Se traçarmos um gráfico da perda em relação a qualquer peso individual ou elemento de tendência, ele se parecerá com a figura mostrada abaixo. Um insight importante do cálculo é que o gradiente indica a taxa de variação da perda, ou seja, a [inclinação](https://en.wikipedia.org/wiki/Slope) da função de perda em relação aos pesos e vieses.\n","\n","Se um elemento gradiente for **positivo**:\n","\n","* **aumentar** ligeiramente o valor do elemento de peso **aumentará** a perda\n","* **diminuir** ligeiramente o valor do elemento de peso **diminuirá** a perda\n","\n","![gradiente positivo](https://i.imgur.com/WLzJ4xP.png)\n","\n","Se um elemento gradiente for **negativo**:\n","\n","* **aumentar** ligeiramente o valor do elemento de peso **diminuirá** a perda\n","* **diminuir** ligeiramente o valor do elemento de peso **aumentará** a perda\n","\n","![negativo=gradiente](https://i.imgur.com/dvG2fxU.png)\n","\n","O aumento ou diminuição da perda pela alteração de um elemento de peso é proporcional ao gradiente da perda em relação a esse elemento. Esta observação forma a base do _algoritmo de otimização de descida do gradiente_ que usaremos para melhorar nosso modelo (_descendo_ ao longo do _gradiente_).\n","\n","Podemos subtrair de cada elemento de peso uma pequena quantidade proporcional à derivada da perda em relação a esse elemento para reduzir ligeiramente a perda."]},{"cell_type":"code","execution_count":77,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1717608404216,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"QQ9cVvevOnUI","outputId":"32f26310-8e6b-49c0-aae7-efadf1b8599f"},"outputs":[{"data":{"text/plain":["(tensor([[ 1.8899,  0.7672,  0.8527],\n","         [-1.0839,  0.0552,  1.3619]], requires_grad=True),\n"," tensor([[ 0.1695,  0.1657,  0.1056],\n","         [-0.0896, -0.0950, -0.0581]]))"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["weight, weight.grad * 1e-5"]},{"cell_type":"code","execution_count":78,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1717608404216,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"rDDvWol9SGJH"},"outputs":[],"source":["with torch.no_grad():\n","  weight -= weight.grad * 1e-5\n","  bias -= bias.grad * 1e-5"]},{"cell_type":"code","execution_count":79,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1717608404217,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"nTRCX1DNhOyB","outputId":"e44f2d25-dce2-4717-cacc-db584af9f70d"},"outputs":[{"data":{"text/plain":["(tensor([[ 1.7204,  0.6015,  0.7471],\n","         [-0.9943,  0.1503,  1.4199]], requires_grad=True),\n"," tensor([ 1.5490, -0.7754], requires_grad=True))"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["weight, bias"]},{"cell_type":"markdown","metadata":{"id":"2GWs8Bxyg-JY"},"source":["Multiplicamos os gradientes com um número muito pequeno (`10^-5` neste caso) para garantir que não modificaremos muito os pesos. Queremos dar um pequeno passo na direção descendente do gradiente, não um salto gigante. Este número é chamado de *taxa de aprendizagem* do algoritmo.\n","\n","Usamos `torch.no_grad` para indicar ao PyTorch que não devemos rastrear, calcular ou modificar gradientes ao atualizar os pesos e tendências."]},{"cell_type":"code","execution_count":80,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1717608404217,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"2fljW4tWhNVk","outputId":"1cf2f4d1-3d4d-4876-e4a5-66c3f53ad248"},"outputs":[{"data":{"text/plain":["tensor(17516.9805, grad_fn=<DivBackward0>)"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["predictions = model(inputs)\n","loss = mse(predictions, targets)\n","loss"]},{"cell_type":"markdown","metadata":{"id":"B76ul2RLhnAw"},"source":["Antes de prosseguir, redefinimos os gradientes para zero invocando o método `.zero_()`. Precisamos fazer isso porque o PyTorch acumula gradientes. Caso contrário, na próxima vez que invocarmos `.backward` na perda, os novos valores de gradiente serão adicionados aos gradientes existentes, o que pode levar a resultados inesperados."]},{"cell_type":"code","execution_count":81,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1717608404217,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"vEdp5QTlhpc0","outputId":"7135b6d5-3975-4a37-cf79-85b3d8a84af5"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n","tensor([0., 0.])\n"]}],"source":["weight.grad.zero_()\n","bias.grad.zero_()\n","print(weight.grad)\n","print(bias.grad)"]},{"cell_type":"markdown","metadata":{"id":"r6Vx6lc6h8an"},"source":["# **Treine o modelo usando gradiente descendente**\n","\n","Como visto acima, reduzimos a perda e melhoramos nosso modelo usando o algoritmo de otimização gradiente descendente. Assim, podemos _treinar_ o modelo usando as seguintes etapas:\n","\n","1. Gere previsões\n","\n","2. Calcule a perda\n","\n","3. Calcular gradientes em relação aos pesos e vieses\n","\n","4. Ajuste os pesos subtraindo uma pequena quantidade proporcional ao gradiente\n","\n","5. Redefina os gradientes para zero\n","\n","Vamos implementar o passo a passo acima."]},{"cell_type":"code","execution_count":82,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1717608404217,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"3DxUVS2ciJA3","outputId":"9af30664-392d-4309-ea22-3ffbcf7a64c1"},"outputs":[{"data":{"text/plain":["tensor([[199.5640,  -2.2312],\n","        [258.8520,  12.8464],\n","        [275.1552,  15.2174],\n","        [230.5379, -43.1918],\n","        [230.2975,  44.4424]], grad_fn=<AddBackward0>)"]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["# Gerando predições\n","predictions = model(inputs)\n","predictions"]},{"cell_type":"code","execution_count":83,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1717608404217,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"r6qfjC5GiNW9","outputId":"aab14341-ac93-4ac2-a6ac-215ebd0406ae"},"outputs":[{"data":{"text/plain":["tensor(17516.9805, grad_fn=<DivBackward0>)"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["# Calculando a perda\n","loss = mse(predictions, targets)\n","loss"]},{"cell_type":"code","execution_count":84,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1717608404217,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"__2_ybBdiY5G","outputId":"a8cbb8be-ef99-48ed-bfd0-0b503aa8a627"},"outputs":[{"data":{"text/plain":["(tensor([[14060.9199, 13476.4492,  8647.9014],\n","         [-7373.1963, -7797.1304, -4753.0581]]),\n"," tensor([162.6813, -86.5834]))"]},"execution_count":84,"metadata":{},"output_type":"execute_result"}],"source":["# Calculando os gradientes\n","loss.backward()\n","weight.grad, bias.grad"]},{"cell_type":"markdown","metadata":{"id":"5go0RqjIinQc"},"source":["Vamos atualizar os pesos e vieses usando os gradientes calculados acima."]},{"cell_type":"code","execution_count":85,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1717608404217,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"Q2RP5MVritsX"},"outputs":[],"source":["# Ajustando os pesos e resetando os gradientes\n","with torch.no_grad():\n","  weight -= weight.grad * 1e-5\n","  bias -= bias.grad * 1e-5\n","  weight.grad.zero_()\n","  bias.grad.zero_()"]},{"cell_type":"code","execution_count":86,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1717608404217,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"a7bJ9NsVjBkL","outputId":"0819dcd7-7f72-4543-8a69-a5e3cdb54115"},"outputs":[{"data":{"text/plain":["(tensor([[ 1.5798,  0.4667,  0.6606],\n","         [-0.9205,  0.2283,  1.4675]], requires_grad=True),\n"," tensor([ 1.5474, -0.7746], requires_grad=True))"]},"execution_count":86,"metadata":{},"output_type":"execute_result"}],"source":["weight, bias"]},{"cell_type":"markdown","metadata":{"id":"LY0Cnz5SjIza"},"source":["Com os novos pesos e vieses, o modelo deveria ter uma perda menor."]},{"cell_type":"code","execution_count":87,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1717608404217,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"QsNxcUERjOfX","outputId":"67917ba6-0056-4739-b789-66dffd5a88a7"},"outputs":[{"data":{"text/plain":["tensor(12126.9658, grad_fn=<DivBackward0>)"]},"execution_count":87,"metadata":{},"output_type":"execute_result"}],"source":["# Calculando a perda\n","predictions = model(inputs)\n","loss = mse(predictions, targets)\n","loss"]},{"cell_type":"markdown","metadata":{"id":"NgbRir9xjWyI"},"source":["Já alcançamos uma redução significativa na perda apenas ajustando ligeiramente os pesos e desvios usando a descida gradiente."]},{"cell_type":"markdown","metadata":{"id":"YJJKmekVjmXd"},"source":["# **Treine para várias épocas**\n","\n","Para reduzir ainda mais a perda, podemos repetir o processo de ajuste dos pesos e desvios usando os gradientes várias vezes. Cada iteração é chamada de _época_. Vamos treinar o modelo por 100 épocas."]},{"cell_type":"code","execution_count":88,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1717608404217,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"MDu5zGSIkpUn"},"outputs":[],"source":["# Treino para 100 épocas\n","for i in range(100):\n","  predictions = model(inputs)\n","  loss = mse(predictions, targets)\n","  loss.backward()\n","  with torch.no_grad():\n","    weight -= weight.grad * 1e-5\n","    bias -= bias.grad * 1e-5"]},{"cell_type":"markdown","metadata":{"id":"JkoKLPNik9Og"},"source":["Verificando que a perda agora é menor:"]},{"cell_type":"code","execution_count":89,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1717608404217,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"qsnJSOL1lCIw","outputId":"b3f33e07-4703-4906-af40-ea7e64b0e375"},"outputs":[{"data":{"text/plain":["tensor(2201.6675, grad_fn=<DivBackward0>)"]},"execution_count":89,"metadata":{},"output_type":"execute_result"}],"source":["# Calculando a perda\n","predictions = model(inputs)\n","loss = mse(predictions, targets)\n","loss"]},{"cell_type":"markdown","metadata":{"id":"qHwIACZklJ5A"},"source":["A perda é agora muito inferior ao seu valor inicial. Vejamos as previsões do modelo e compare-as com as metas."]},{"cell_type":"code","execution_count":90,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1717608404217,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"oLocfdqTl5bQ","outputId":"fce14246-e24c-471b-fe5b-78a3b82602ad"},"outputs":[{"data":{"text/plain":["tensor([[ 56.,  70.],\n","        [ 81., 101.],\n","        [119., 133.],\n","        [ 22.,  37.],\n","        [103., 119.]])"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["targets"]},{"cell_type":"code","execution_count":91,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1717608404217,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"5ofuh7Ril64g","outputId":"15c11bb7-ddfb-438b-9311-9cfe9b843db2"},"outputs":[{"data":{"text/plain":["tensor([[101.3021,  45.5736],\n","        [143.2536,  61.7206],\n","        [192.6663, 104.8113],\n","        [ 54.0299,  15.9840],\n","        [168.6469,  74.8305]], grad_fn=<AddBackward0>)"]},"execution_count":91,"metadata":{},"output_type":"execute_result"}],"source":["predictions"]},{"cell_type":"markdown","metadata":{"id":"DQE_EWWbmd0I"},"source":["As previsões estão agora bastante próximas das variáveis-alvo. Podemos obter resultados ainda melhores treinando por mais algumas épocas."]},{"cell_type":"markdown","metadata":{"id":"XUPQFnnFm079"},"source":["# **Regressão linear usando PyTorch integrado**\n","\n","Implementamos regressão linear e modelo de gradiente descendente usando algumas operações básicas de tensor. No entanto, como esse é um padrão comum no aprendizado profundo, o PyTorch fornece várias funções e classes integradas para facilitar a criação e o treinamento de modelos com apenas algumas linhas de código.\n","\n","Vamos começar importando o pacote `torch.nn` do PyTorch, que contém classes utilitárias para construção de redes neurais."]},{"cell_type":"code","execution_count":92,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1717608404217,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"ZkMkh0Y-nPXU"},"outputs":[],"source":["import torch.nn as nn"]},{"cell_type":"code","execution_count":93,"metadata":{"executionInfo":{"elapsed":314,"status":"ok","timestamp":1717608404523,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"cK5R-kHynUKM"},"outputs":[],"source":["# Input (temp, rainfall, humidity)\n","inputs = np.array([[73, 67, 43],\n","                   [91, 88, 64],\n","                   [87, 134, 58],\n","                   [102, 43, 37],\n","                   [69, 96, 70],\n","                   [74, 66, 43],\n","                   [91, 87, 65],\n","                   [88, 134, 59],\n","                   [101, 44, 37],\n","                   [68, 96, 71],\n","                   [73, 66, 44],\n","                   [92, 87, 64],\n","                   [87, 135, 57],\n","                   [103, 43, 36],\n","                   [68, 97, 70]],\n","                  dtype='float32')\n","\n","# Targets (apples, oranges)\n","targets = np.array([[56, 70],\n","                    [81, 101],\n","                    [119, 133],\n","                    [22, 37],\n","                    [103, 119],\n","                    [57, 69],\n","                    [80, 102],\n","                    [118, 132],\n","                    [21, 38],\n","                    [104, 118],\n","                    [57, 69],\n","                    [82, 100],\n","                    [118, 134],\n","                    [20, 38],\n","                    [102, 120]],\n","                   dtype='float32')\n","\n","inputs = torch.from_numpy(inputs)\n","targets = torch.from_numpy(targets)"]},{"cell_type":"code","execution_count":94,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":315,"status":"ok","timestamp":1717608404524,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"q25kk6nrn5bF","outputId":"58b6021f-36e6-4436-c157-62e39d42ea35"},"outputs":[{"data":{"text/plain":["torch.Size([15, 3])"]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["inputs.shape"]},{"cell_type":"markdown","metadata":{"id":"IbXfEL0yn9qo"},"source":["# **Dataset and DataLoader**"]},{"cell_type":"code","execution_count":95,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1717608404524,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"3E9EA5a5WR6i"},"outputs":[],"source":["from torch.utils.data import TensorDataset"]},{"cell_type":"code","execution_count":96,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1717608404524,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"psponcQKWWbQ","outputId":"a29126ea-6d86-41cd-d952-519b9a36cb42"},"outputs":[{"data":{"text/plain":["(tensor([[ 73.,  67.,  43.],\n","         [ 91.,  88.,  64.],\n","         [ 87., 134.,  58.]]),\n"," tensor([[ 56.,  70.],\n","         [ 81., 101.],\n","         [119., 133.]]))"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["train_ds = TensorDataset(inputs, targets)\n","train_ds[0:3]"]},{"cell_type":"markdown","metadata":{"id":"RocR5JBEWmSd"},"source":["O `TensorDataset` nos permite acessar uma pequena seção dos dados de treinamento usando a notação de indexação de matriz (`[0:3]` no código acima). Ele retorna uma tupla com dois elementos. O primeiro elemento contém as variáveis de entrada para as linhas selecionadas e o segundo contém os alvos."]},{"cell_type":"markdown","metadata":{"id":"O7Yi71BCWyhr"},"source":["Também criaremos um `DataLoader`, que pode dividir os dados em lotes de tamanho predefinido durante o treinamento. Ele também fornece outros utilitários, como embaralhamento e amostragem aleatória dos dados."]},{"cell_type":"code","execution_count":97,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1717608404524,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"Q8zoQxpNW0Yo"},"outputs":[],"source":["from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":98,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1717608404524,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"7aDVCoAbXHi2"},"outputs":[],"source":["batch_size = 5\n","train_dl = DataLoader(train_ds, batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":99,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1717608404524,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"O9KPPrLuXICX","outputId":"c7bb5e4e-47f7-4a54-9b37-4d32e49be78b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Lote\n","tensor([[ 88., 134.,  59.],\n","        [ 91.,  87.,  65.],\n","        [103.,  43.,  36.],\n","        [ 73.,  66.,  44.],\n","        [102.,  43.,  37.]])\n","tensor([[118., 132.],\n","        [ 80., 102.],\n","        [ 20.,  38.],\n","        [ 57.,  69.],\n","        [ 22.,  37.]])\n","Lote\n","tensor([[ 73.,  67.,  43.],\n","        [ 92.,  87.,  64.],\n","        [ 69.,  96.,  70.],\n","        [ 87., 135.,  57.],\n","        [101.,  44.,  37.]])\n","tensor([[ 56.,  70.],\n","        [ 82., 100.],\n","        [103., 119.],\n","        [118., 134.],\n","        [ 21.,  38.]])\n","Lote\n","tensor([[ 68.,  96.,  71.],\n","        [ 68.,  97.,  70.],\n","        [ 91.,  88.,  64.],\n","        [ 87., 134.,  58.],\n","        [ 74.,  66.,  43.]])\n","tensor([[104., 118.],\n","        [102., 120.],\n","        [ 81., 101.],\n","        [119., 133.],\n","        [ 57.,  69.]])\n"]}],"source":["# Carregando os três lotes de dados do conjunto\n","for xb, yb in train_dl:\n","  print('Lote')\n","  print(xb)\n","  print(yb)"]},{"cell_type":"markdown","metadata":{"id":"65D_lsBbXYxX"},"source":["# **Classe nn.Linear**"]},{"cell_type":"code","execution_count":100,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1717608404524,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"gXbAS7SmYLzP","outputId":"4625466a-9567-4a90-f03a-b3cefd3a1f84"},"outputs":[{"name":"stdout","output_type":"stream","text":["Parameter containing:\n","tensor([[-0.1950,  0.4197,  0.2940],\n","        [ 0.4141, -0.1025, -0.4840]], requires_grad=True)\n","Parameter containing:\n","tensor([-0.2339, -0.0552], requires_grad=True)\n"]}],"source":["# nn.Linear(input_size, num_classes)\n","# input_size = humidade, temperatura, chuva\n","# num_classes = rendimento de maçãs e laranjas\n","model = nn.Linear(3,2)\n","# weight e bias aqui são parâmetros padrão\n","print(model.weight)\n","print(model.bias)"]},{"cell_type":"code","execution_count":102,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1717608409846,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"D27XQvlgbo3_","outputId":"a94f10a4-66ae-4849-ba50-faa5f6ba7fc1"},"outputs":[{"data":{"text/plain":["[Parameter containing:\n"," tensor([[-0.1950,  0.4197,  0.2940],\n","         [ 0.4141, -0.1025, -0.4840]], requires_grad=True),\n"," Parameter containing:\n"," tensor([-0.2339, -0.0552], requires_grad=True)]"]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["list(model.parameters())"]},{"cell_type":"code","execution_count":103,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1717608411040,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"eXomeOrqbzPF","outputId":"c6abe9e5-73aa-496b-eea8-f5d5006348d4"},"outputs":[{"data":{"text/plain":["tensor([[ 26.2959,   2.4900],\n","        [ 37.7744,  -2.3740],\n","        [ 56.0985,  -5.8421],\n","        [  8.8035,  19.8622],\n","        [ 47.1860, -15.2074],\n","        [ 25.6812,   3.0066],\n","        [ 37.6486,  -2.7554],\n","        [ 56.1975,  -5.9121],\n","        [  9.4182,  19.3456],\n","        [ 47.6749, -16.1055],\n","        [ 26.1702,   2.1085],\n","        [ 37.1596,  -1.8574],\n","        [ 56.2243,  -5.4606],\n","        [  8.3145,  20.7603],\n","        [ 47.8007, -15.7240]], grad_fn=<AddmmBackward0>)"]},"execution_count":103,"metadata":{},"output_type":"execute_result"}],"source":["preds = model(inputs)\n","preds"]},{"cell_type":"markdown","metadata":{"id":"N-PLd_6dcH0-"},"source":["# **Função de Perda (Loss)**"]},{"cell_type":"code","execution_count":110,"metadata":{"executionInfo":{"elapsed":296,"status":"ok","timestamp":1717608488313,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"ojbrfYxGcLuY"},"outputs":[],"source":["import torch.nn.functional as F"]},{"cell_type":"code","execution_count":111,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1717608490210,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"cwZksak3cOtd"},"outputs":[],"source":["loss_fn = F.mse_loss"]},{"cell_type":"code","execution_count":112,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1717608491874,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"nvxcO_pgcRlL","outputId":"34ca170b-e2fd-4eab-dedf-e5585570154f"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(6275.7642, grad_fn=<MseLossBackward0>)\n"]}],"source":["loss = loss_fn(model(inputs), targets)\n","print(loss)"]},{"cell_type":"markdown","metadata":{"id":"BTK69zyYcbAv"},"source":["# **Otimizador**"]},{"cell_type":"markdown","metadata":{"id":"-adRRzlgcd2O"},"source":["Em vez de manipular manualmente os pesos e as tendências do modelo usando gradientes, podemos usar o otimizador `optim.SGD`. SGD é a abreviação de “stochastic gradient descent” (descida de gradiente estocástica). O termo _stochastic_ indica que as amostras são selecionadas em lotes aleatórios em vez de em um único grupo."]},{"cell_type":"code","execution_count":113,"metadata":{"executionInfo":{"elapsed":1642,"status":"ok","timestamp":1717608581187,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"wrQvO1m5ciEy"},"outputs":[],"source":["opt = torch.optim.SGD(model.parameters(), lr=1e-5)"]},{"cell_type":"markdown","metadata":{"id":"idPzbiwhcwdh"},"source":["Observe que `model.parameters()` é passado como um argumento para `optim.SGD` para que o otimizador saiba quais matrizes devem ser modificadas durante a etapa de atualização. Além disso, podemos especificar uma taxa de aprendizado que controla o valor pelo qual os parâmetros são modificados."]},{"cell_type":"markdown","metadata":{"id":"HHtvBjVuczzB"},"source":["# **Treinando o Modelo**"]},{"cell_type":"markdown","metadata":{"id":"88f7fPWJdmN3"},"source":["Agora estamos prontos para treinar o modelo. Seguiremos o mesmo processo para implementar a descida de gradiente:\n","\n","1. Gerar previsões\n","\n","2. Calcular a perda\n","\n","3. Calcule gradientes com relação aos pesos e vieses\n","\n","4. Ajuste os pesos subtraindo uma pequena quantidade proporcional ao gradiente\n","\n","5. Redefinir os gradientes para zero\n","\n","A única mudança é que trabalharemos com lotes de dados em vez de processar todos os dados de treinamento em cada iteração. Vamos definir uma função utilitária `fit` que treina o modelo para um determinado número de épocas."]},{"cell_type":"code","execution_count":114,"metadata":{"executionInfo":{"elapsed":869,"status":"ok","timestamp":1717608917395,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"IwYKQ5bhc44g"},"outputs":[],"source":["# Função utilitária para treinar o modelo\n","def fit(num_epochs, model, loss_fn, opt, train_dl):\n","\n","  # Repetindo o processo para o número de épocas determinado\n","  for epoch in range(num_epochs):\n","\n","    # Treinando com os lotes (batches) de dados\n","    for xb, yb in train_dl:\n","\n","      # Gerando predições\n","      predictions = model(xb)\n","\n","      # Calculando a perda\n","      loss = loss_fn(predictions, yb)\n","\n","      # Calculando os gradientes\n","      loss.backward()\n","\n","      # Atualizando os parâmetros utilizando os gradientes\n","      opt.step()\n","\n","      # Resetando os gradientes para zero\n","      opt.zero_grad()\n","\n","      if (epoch+1) % 10 == 0:\n","        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"]},{"cell_type":"markdown","metadata":{"id":"Sh0FKfc7eBYm"},"source":["Alguns aspectos a serem observados acima:\n","\n","* Usamos o carregador de dados definido anteriormente para obter lotes de dados para cada iteração.\n","\n","* Em vez de atualizar os parâmetros (pesos e bias) manualmente, usamos `opt.step` para realizar a atualização e `opt.zero_grad` para redefinir os gradientes para zero.\n","\n","* Também adicionamos uma instrução de registro que imprime a perda do último lote de dados a cada 10 épocas para acompanhar o progresso do treinamento. O `loss.item` retorna o valor real armazenado no tensor de perda.\n","\n","Vamos treinar o modelo para 100 épocas."]},{"cell_type":"code","execution_count":115,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":535,"status":"ok","timestamp":1717609143633,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"mCMQWuT1e2ov","outputId":"5039c9b3-c489-4565-de96-691e0e11b37e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [10/100], Loss: 377.4854\n","Epoch [10/100], Loss: 358.4431\n","Epoch [10/100], Loss: 629.1356\n","Epoch [20/100], Loss: 309.6006\n","Epoch [20/100], Loss: 393.0907\n","Epoch [20/100], Loss: 239.9509\n","Epoch [30/100], Loss: 155.7235\n","Epoch [30/100], Loss: 226.3564\n","Epoch [30/100], Loss: 298.7207\n","Epoch [40/100], Loss: 168.9968\n","Epoch [40/100], Loss: 170.6913\n","Epoch [40/100], Loss: 161.3027\n","Epoch [50/100], Loss: 54.1205\n","Epoch [50/100], Loss: 159.2005\n","Epoch [50/100], Loss: 177.6234\n","Epoch [60/100], Loss: 149.5891\n","Epoch [60/100], Loss: 97.9553\n","Epoch [60/100], Loss: 49.1023\n","Epoch [70/100], Loss: 79.7201\n","Epoch [70/100], Loss: 79.8000\n","Epoch [70/100], Loss: 73.8776\n","Epoch [80/100], Loss: 57.8007\n","Epoch [80/100], Loss: 45.1989\n","Epoch [80/100], Loss: 92.0613\n","Epoch [90/100], Loss: 67.2296\n","Epoch [90/100], Loss: 34.1094\n","Epoch [90/100], Loss: 60.7971\n","Epoch [100/100], Loss: 34.6929\n","Epoch [100/100], Loss: 57.3966\n","Epoch [100/100], Loss: 49.2684\n"]}],"source":["fit(100, model, loss_fn, opt, train_dl)"]},{"cell_type":"code","execution_count":116,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1717609265686,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"MEZKA652e65O","outputId":"18b0d3e8-694e-48d5-eef8-443ca11cfe9b"},"outputs":[{"data":{"text/plain":["tensor([[ 57.5618,  72.4374],\n","        [ 81.1075,  96.2386],\n","        [119.1783, 139.6667],\n","        [ 24.5695,  48.8064],\n","        [ 98.0259, 104.5331],\n","        [ 56.3820,  71.4879],\n","        [ 80.7590,  95.4271],\n","        [119.3867, 139.8368],\n","        [ 25.7493,  49.7559],\n","        [ 98.8572, 104.6710],\n","        [ 57.2133,  71.6258],\n","        [ 79.9276,  95.2892],\n","        [119.5268, 140.4783],\n","        [ 23.7381,  48.6685],\n","        [ 99.2057, 105.4826]], grad_fn=<AddmmBackward0>)"]},"execution_count":116,"metadata":{},"output_type":"execute_result"}],"source":["preds = model(inputs)\n","preds"]},{"cell_type":"code","execution_count":117,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1717609277518,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"PWV8L5P1fZee","outputId":"e42afae4-dc05-4bd2-d317-c0eb43d7ce42"},"outputs":[{"data":{"text/plain":["tensor([[ 56.,  70.],\n","        [ 81., 101.],\n","        [119., 133.],\n","        [ 22.,  37.],\n","        [103., 119.],\n","        [ 57.,  69.],\n","        [ 80., 102.],\n","        [118., 132.],\n","        [ 21.,  38.],\n","        [104., 118.],\n","        [ 57.,  69.],\n","        [ 82., 100.],\n","        [118., 134.],\n","        [ 20.,  38.],\n","        [102., 120.]])"]},"execution_count":117,"metadata":{},"output_type":"execute_result"}],"source":["targets"]},{"cell_type":"markdown","metadata":{"id":"S1fMIJU8fhZ8"},"source":["De fato, as previsões estão bem próximas de nossas metas. Treinamos um modelo razoavelmente bom para prever o rendimento das safras de maçãs e laranjas, observando a temperatura média, a precipitação e a umidade em uma região. Podemos usá-lo para fazer previsões de rendimentos de colheitas para novas regiões passando um lote contendo uma única linha de entrada."]},{"cell_type":"code","execution_count":118,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":315,"status":"ok","timestamp":1717609337182,"user":{"displayName":"Any Caroliny","userId":"09380659905787657675"},"user_tz":180},"id":"fSlOfp2CfeOg","outputId":"862d01ec-e6d2-406e-9afc-6367cc205080"},"outputs":[{"data":{"text/plain":["tensor([[53.9853, 68.7613]], grad_fn=<AddmmBackward0>)"]},"execution_count":118,"metadata":{},"output_type":"execute_result"}],"source":["model(torch.tensor([[75, 63, 44.]]))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNOigfx28BcQnU5SmUadZVr","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
